
# N-LeTaxity: Real-Time NYC Taxi Data Pipeline

## ğŸ§­ Project Goal
Simulate and stream near real-time NYC taxi data using a Python script, and ingest that data into AWS services (S3 and Redshift) for analysis and visualization. The system should start small (1 record/sec) but be designed to scale for high-throughput streaming in the future.

---

## âœ… Architecture Overview

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  Your PC / EC2 Instance   â”‚
â”‚  (Python Simulator)       â”‚
â”‚  â”€ generate_trip_event()  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
             â”‚
             â–¼
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Amazon Kinesis Firehose   â”‚
â”‚ â”€ Buffers + Batches Data  â”‚
â”‚ â”€ Sends to multiple sinks â”‚
â•°â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â•¯
       â”‚            â”‚
       â–¼            â–¼
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚   Amazon   â”‚  â”‚     Amazon         â”‚
â”‚     S3     â”‚  â”‚     Redshift       â”‚
â”‚  (Raw Zone)â”‚  â”‚ (Analytics Layer)  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

    ğŸ” Future Add-Ons:
    - AWS Lambda (transformation)
    - Kinesis Analytics (real-time SQL)
    - QuickSight/Tableau (dashboards)
```

---

## ğŸ“„ Streaming Data Schema (JSON Format)

```json
{
  "trip_id": "cab_1728337",
  "pickup_time": "2025-03-23 12:15:30",
  "dropoff_time": "2025-03-23 12:29:52",
  "PULocationID": 12,
  "DOLocationID": 35,
  "passenger_count": 2,
  "fare_amount": 18.75,
  "payment_type": 1
}
```

---

## ğŸ—‚ Project Folder Structure (Planned)

```
N-LeTaxity/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ batch/
â”‚   â”œâ”€â”€ streaming/
â”‚   â”‚   â””â”€â”€ streaming_simulator.py
â”‚   â””â”€â”€ helpers/
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ glue/
â”‚   â”œâ”€â”€ emr/
â”‚   â”œâ”€â”€ kinesis/
â”‚   â”œâ”€â”€ redshift/
â”‚   â””â”€â”€ lambda/
â”œâ”€â”€ analytics/
â”‚   â”œâ”€â”€ quicksight/
â”‚   â””â”€â”€ tableau/
â”œâ”€â”€ sql/
â”œâ”€â”€ data_samples/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture_diagram.png (TBD)
â””â”€â”€ README.md
```

---

## ğŸ›  Task Breakdown (Checklist Style)

### Phase 1: Project Initialization
- [x] Decide project name: `N-LeTaxity`
- [x] Set up project folder structure
- [x] Create GitHub repo and connect local project
- [x] Add README and commit structure

### Phase 2: Build Streaming Simulator
- [x] Define simplified schema for streaming
- [x] Install `boto3`, `faker` on local environment
- [x] Write `streaming_simulator.py` to generate 1 trip/sec
- [x] Connect to AWS Kinesis Firehose
- [ ] Parameterize stream name and message rate
- [ ] Add basic logging and error handling

### Phase 3: AWS Infrastructure
- [x] Create Kinesis Firehose delivery stream
- [ ] Configure destination: S3 (initial), Redshift (next)
- [ ] Verify delivery to S3 bucket (raw data)
- [ ] Create Redshift table for streamed schema
- [ ] Configure Firehose to deliver to Redshift (if used)

### Phase 4: Data Validation
- [ ] Query S3 using Athena or Glue
- [ ] Validate schema and data format
- [ ] Create Glue Catalog table for S3 bucket (optional)

### Phase 5: Visualization (Future)
- [ ] Connect Redshift to QuickSight
- [ ] Create sample dashboard (trip volume, avg fare, etc.)
- [ ] Optional: Add Tableau integration

### Phase 6: Scalability Planning
- [ ] Increase simulator rate (10+ msgs/sec)
- [ ] Migrate simulator to EC2
- [ ] Add multithreading to simulator (optional)
- [ ] Add monitoring (CloudWatch) for Firehose delivery

---

## ğŸ“Œ Notes
- Use JSON output for simulator to simplify parsing
- Keep trip timestamps realistic (pickup < dropoff, UTC format)
- Leave room for stream transformation via Lambda in the future

---

Let me know when you want to tag a release, create a PR for a module, or automate parts of the pipeline.