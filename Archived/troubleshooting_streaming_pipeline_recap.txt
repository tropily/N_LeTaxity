Troubleshooting Recap: Streaming Data Pipeline (Firehose + Lambda + S3 + Athena)
Date: 2025-03-26 01:47:21

1. Lambda Transformation Succeeded But Records Ended in Error Folder
---------------------------------------------------------------------
✔️ Symptom: Records ended up in S3 error folders such as:
   - errorprocessing-failed/
   - errorformat-conversion-failed/

✔️ Root Causes & Fixes:
   a. Missing base64 decoding:
      - Fix: 
        decoded_data = base64.b64decode(record['data']).decode('utf-8').strip()

   b. Incorrect datetime format:
      - Fix: Convert pickup/dropoff_datetime to ISO 8601 with 'T':
        pickup_dt.strftime("%Y-%m-%dT%H:%M:%S")

   c. Missing or incorrect partition keys:
      - Fix: Add correct metadata.partitionKeys to each output record:
        "metadata": {
            "partitionKeys": {
                "year": str(payload["year"]),
                "month": str(payload["month"]),
                "day": str(payload["day"]),
                "hour": str(payload["hour"])
            }
        }

2. Best Practices to Avoid Similar Issues
-----------------------------------------
✔️ Start simple: Test Firehose without Lambda first.
✔️ Log all steps in Lambda: decoded input, transformed output, errors.
✔️ Use ISO 8601 format for timestamps with 'T'.
✔️ Match Lambda output fields exactly to Athena table schema.
✔️ Ensure Firehose prefix and Athena partition projection match.
✔️ Use Parquet format for scalable querying if possible.
✔️ Use the Lambda console to test with mock event JSON.
✔️ Monitor CloudWatch logs and Firehose logs for error context.

Next Steps:
-----------
- Build Athena Views & QuickSight dashboards
- Schedule Glue Jobs or Lambda functions for aggregation or alerting
- Set up notification for failed deliveries if needed

